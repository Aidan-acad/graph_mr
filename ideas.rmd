---
title: Resolving direct causal effects from causal networks
author: Gibran Hemani
date: "`r Sys.Date()`"
output: 
  html_document: 
    toc: true
  pdf_document:
    keep_tex: true
    toc: true
bibliography: ideas.bib
---


```{r, echo=FALSE, cache=FALSE}

# http://www.mathpages.com/home/kmath198/2-1/2-1.htm
# http://videolectures.net/gpip06_mackay_gpb/

suppressPackageStartupMessages(library(knitr))
suppressPackageStartupMessages(library(tidyr))
suppressPackageStartupMessages(library(ggplot2))

read_chunk("functions.r")
source("functions.r")
opts_chunk$set(warning=FALSE, message=FALSE, cache=TRUE, echo=FALSE)
set.seed(1234)

```

**Code available at:** [https://scmv-ieugit.epi.bris.ac.uk/gh13047/graph_mr](https://scmv-ieugit.epi.bris.ac.uk/gh13047/graph_mr)

## Summary

Suppose we have complete summary statistics for an arbitrary number of traits, and each trait has valid instruments. Mendelian randomisation can be used to calculate the causal relationships of $M \times M$ pairs of traits, thereby constructing a matrix of *total* effects of each trait on each of the other traits. This paper introduces a method to deconvolve this matrix to obtain the set of all direct causal effects between the traits. It goes on to show that the statistical power of identifying causal relationships between traits improves substantially by chaining together the direct effects on the deconvolved pathway, when compared to evaluating the total effect as is typical in Mendelian randomisation.


## Introduction


Many methods exist that attempt to decompose correlation matrices into a set of terse direct correlations, with a view towards obtaining the minimum set of correlations that can explain the observed matrix. This process is known as deconvolution [@Feizi2013] [describe other methods in more detail]. A typical use case in biology is to calculate the correlation matrix of gene expression levels, and deconvolve to identify genes that drive networks. The application of matrix deconvolution to the context of causal inference in Mendelian randomisation (MR), as shown in Figre 1, could have the following attractive features:

- Identify direct pathways through which a particular exposure influences an outcome
- Identify instances of partial mediation, which might suggest that there are unknown variables that remain to be uncovered that mediate the path from exposure to outcome
- Potentially improve power in identifying causal relationships between traits that are on the same causal pathway

Growth in available GWAS summary data on phenotypes is on a steep trajectory, such that we may soon be asymptoting towards a situation where we can use two-sample MR to test 'everything against everything'. What this entails is that we could construct a pairwise causal relationship of all (available) traits (e.g. see Figure 1a,b). Each element in such a matrix would represent the *total* causal effect between the two traits. The purpose of this paper is to explore how to deconvolve this set of *total* effects into a terse set of *direct* effects. 

Attempts at constructing networks using MR have been proposed [@Burgess2015], based on the idea of mediation by MR [@Relton2012], though implementation of this method to more than three variables has not been demonstrated. While existing deconvolution methods can be applied to an arbitrary number of traits, they tend to require that the initial matrix is symmetrical, and they often do not incorporate information that disentangles correlation from causation. The setting for this paper assumes the contrary in both counts. The matrix of total MR effects is asymmetrical because the estimate of A on B (instrumented by SNPs that relate to A) is not the same as the estimate of B on A (instrumented by SNPs that relate to B). Further, each element in the matrix of total effects is assumed to be a causal estimate.




## Methods


### Assumptions

1. It is important to acknowledge that, though beyond the scope of this paper, the premise of obtaining the causal effect of 'everything on everything' requires methodological advancements to address many issues, including but not limited to multiple testing, consideration of phenotypic definitions, and incorporating temporal effects and critical effect periods.

2. We begin by assuming that the causal effect estimates of each element in the *total* effects matrix is unbiased (Figure 1a,b). In practice it is not yet clear how to ensure this, though methods are continually developing to improve the reliability of MR estimates to violations of its main assumptions [@Bowden2015; @Bowden2016a; @Bowden2016b; @Hemani2016].


### Direct and total effects

The latter can be summarised as follows. Suppose there are six variables of interest, 1-6, and the causal relationships are

```
1 -> 2
2 -> 3
3 -> 4
4 -> 5
5 -> 6
```

This can be depicted in graph form as in Figure 1e. If, however, we performed MR of `1 -> 3`, `1 -> 4`, etc, we would identify associations because they exist indirectly. Hence, after testing everything against everything our graph would look like Figure 1d.

MR for mediation (AKA network MR) operates in the case where there are three phenotypic variables [@Burgess2015a] as follows. The direct effect of trait 1 on trait 2, $\beta_{1 \Rightarrow 2}$, is obtained from:

$$
\beta_{1 \Rightarrow 2} = \beta_{1 \rightarrow 2} - \beta_{1 \rightarrow 3}\beta_{3 \rightarrow 2}
$$

With four variables it looks like:

$$
\begin{aligned}
\beta_{1 \Rightarrow 2} = \beta_{1 \rightarrow 2} & - \beta_{1 \rightarrow 3}\beta_{3 \rightarrow 4}\beta_{4 \rightarrow 2} \\
& - \beta_{1 \rightarrow 3} \beta_{3 \rightarrow 2} \\
& - \beta_{1 \rightarrow 4} \beta_{4 \rightarrow 2}
\end{aligned}
$$

With five variables it looks like:

$$
\begin{aligned}
\beta_{1 \Rightarrow 2} = \beta_{1 \rightarrow 2} & - \beta_{1 \rightarrow 3}\beta_{3 \rightarrow 4}\beta_{4 \rightarrow 5}\beta_{5 \rightarrow 2} \\
& - \beta_{1 \rightarrow 3} \beta_{3 \rightarrow 4} \beta_{4 \rightarrow 2} \\
& - \beta_{1 \rightarrow 3} \beta_{3 \rightarrow 5} \beta_{5 \rightarrow 2} \\
& - \beta_{1 \rightarrow 4} \beta_{4 \rightarrow 5} \beta_{5 \rightarrow 2} \\
& - \beta_{1 \rightarrow 3} \beta_{3 \rightarrow 5} \beta_{4 \rightarrow 2} \\
& - \beta_{1 \rightarrow 3} \beta_{3 \rightarrow 2} \\
& - \beta_{1 \rightarrow 4} \beta_{4 \rightarrow 2} \\
& - \beta_{1 \rightarrow 5} \beta_{5 \rightarrow 2}
\end{aligned}
$$

and this is performed for each of the $5 \times 5$ possible pairwise combinations of variables, ultimately reducing a matrix of total effect relationships, $R_{t}$ e.g.



```{r, fig.cap="Simulated causal relationships"}

dat1 <- init_dat(500000, 5)
dat1 <- make_edge(1, 2, -1, dat1)
dat1 <- make_edge(2, 3, -2, dat1)
dat1 <- make_edge(3, 4, 1, dat1)
dat1 <- make_edge(4, 5, 3, dat1)

res1 <- graph_mr(dat1)
round(res1$b, 1)
```

into a matrix of direct relationships, $R_{d}$ e.g.

```{r }
dat1$r
```

There are two potential drawbacks with the MR for mediation approach. First, the combinatorial increase in the number of terms that are required for calculating the direct effects gets large very quickly. For example, for a graph with 10 variables there are 52 unique paths for each of the 100 elements in the matrix, and identifying those paths itself is a computationally slow process. Second, perhaps more importantly, this method may not actually generalise beyond the three-variable graph.

\newpage


## Simulations

Assume that there are $M$ variables measured in $N$ samples represented in a $N \times M$ matrix $P$. Further, each variable has a valid instrument, hence there are $M$ instruments also, represented in a $N \times M$ matrix $G$. As stated above, in this analysis I am assuming that every causal estimate made by MR is reliable.

DAGs are simulated such that the $M$ variables are related to each other by random causal effects. Cycles are avoided. Following on, two-stage least squares is used to calculate all pairwise causal relationships e.g.

$$
R_{t}(1 \rightarrow 2) = \frac{cov(P_{,2}, G_{,1} cov(P_{,1}, G_{,1} / var(G_{,1})))} { var(G_{,1} cov(P_{,1}, G_{,1} / var(G_{,1}))) }	
$$

Three methods are then used to try to deconvolve the graph $R_{t}$ into $R_{d}$.

### Method 1 - mediation by MR

This is as described in [Relton2012] and [Burgess2015a].


### Method 2 - inversion

Simply a method to orthogonalise the matrix by 

$$
R_{d} = R_{t}^{-1}
$$

If $R_{t}$ were a variance covariance matrix then this method is known as obtaining the precision matrix.

### Method 3 - Feizi deconvolution

In [@Feizi2013] a method is outlined for network deconvolution that is primarily aimed at correlation matrices (i.e. symmetric, non-causal versions of $R_{t}$). The method is:

$$
R_{d} = R_{t}(I + R_{t})^{-1}
$$

### Standard errors

To obtain the standard errors of the direct effects for the inversion method, we can use bootstrapping. Here, each element in the matrix of total effects is resampled with $R_{t}(i,j)* \sim N(R_{t}(i,j), se(R_{t}(i,j)))$. The inversion method is then applied to the resampled matrix $R_{t}*$ and the results $R_{d}*$ are stored. This is performed 1000 times to obtain a distribution of effects for each element of the $R_{d}$ matrix. The standard deviation of the distribution from each element is taken to be the standard error of that direct effect estimate. 


\newpage

## Results

The analysis is divided into two sections. First, a demonstration that in most cases the inversion method is rapid and returns the true direct effects; and second, an evaluation of statistical power, particularly in comparing the ability to detect a total effect vs detecting a chain of .

### Simulation 1 - three-variable networks

```{r }

dat <- init_dat(500000, 3)
dat <- make_edge(1,2,2, dat)
dat <- make_edge(2,3,3, dat)
dat <- make_edge(1,3,7, dat)
res <- graph_mr(dat)
res1 <- mediation_method(res)
res2 <- inversion_method(res)
res3 <- deconvolution_method(res)

```

Simulate 500000 samples with three variables, with the following real causal structure

```{r, fig.cap="Three variables, N=500000" }

par(mfrow=c(2,3))
plot_from_matrix(dat$r, "True graph")
plot_from_matrix(res$b, "Total effects")
plot(1, type="n", axes=F, xlab="", ylab="")
plot_from_matrix(res1, "Mediation method")
plot_from_matrix(res2, "Inversion method")
plot_from_matrix(res3, "Feizi method")

```

The three methods agree on the causal structures as the true graph. The total effects graph has much larger effects for $1 \rightarrow 3$ as expected, because this is the sum of the direct and indirect effects. The Feizi method shrinks the effect sizes somewhat.

* * *

### Simulation 2 - four-variable networks

```{r }

dat <- init_dat(500000, 4)
dat <- make_edge(1,2,2, dat)
dat <- make_edge(2,3,3, dat)
dat <- make_edge(1,3,7, dat)
dat <- make_edge(1,4,-2, dat)
dat <- make_edge(2,4,-4, dat)

res <- graph_mr(dat)
res1 <- mediation_method(res)
res2 <- inversion_method(res)
res3 <- deconvolution_method(res)

```

Simulate 500000 samples with three variables, with the following real causal structure

```{r, fig.cap="Graphs of four variables, N=500000" }

par(mfrow=c(2,3))
plot_from_matrix(dat$r, "True graph")
plot_from_matrix(res$b, "Total effects")
plot(1, type="n", axes=F, xlab="", ylab="")
plot_from_matrix(res1, "Mediation method")
plot_from_matrix(res2, "Inversion method")
plot_from_matrix(res3, "Feizi method")

```

Similar story to the three variable network, but of course there are some paths in the $R_{t}$ which should not be present in the estimates of $R_{d}$. Another way to evaluate agreement is to plot the values of the matrix elements against the true matrix elements, e.g.

```{r, fig.cap="Matrix elements of four variables, N=500000"}

par(mfrow=c(2,2))
plot(res1 ~ dat$r, xlab="True", ylab="Mediation")
plot(res2 ~ dat$r, xlab="True", ylab="Inversion")
plot(res3 ~ dat$r, xlab="True", ylab="Feizi")
plot(res$b ~ dat$r, xlab="True", ylab="Total effects")

```

Here we can see that the mediation and inversion methods are reasonably accurate, but the Feizi method seems to be very close to the total effects.


* * *

### Simulation 3 - four-variable networks, more complex

```{r }

dat <- init_dat(500000, 4)
dat <- make_edge(1,2,2, dat)
dat <- make_edge(2,3,3, dat)
dat <- make_edge(2,4,7, dat)
dat <- make_edge(1,3,4, dat)
dat <- make_edge(3,4,5, dat)
dat <- make_edge(1,4,6, dat)

res <- graph_mr(dat)
res1 <- mediation_method(res)
res2 <- inversion_method(res)
res3 <- deconvolution_method(res)

```

Here the graph is slightly more complex

```{r, fig.cap="Graphs of four variables, N=500000" }

par(mfrow=c(2,3))
plot_from_matrix(dat$r, "True graph")
plot_from_matrix(res$b, "Total effects")
plot(1, type="n", axes=F, xlab="", ylab="")
plot_from_matrix(res1, "Mediation method")
plot_from_matrix(res2, "Inversion method")
plot_from_matrix(res3, "Feizi method")

```

And it can be seen that the mediation method does not resolve the direct effects accurately for one particular edge

```{r, fig.cap="Matrix elements of four variables, N=500000"}

par(mfrow=c(2,2))
plot(res1 ~ dat$r, xlab="True", ylab="Mediation")
plot(res2 ~ dat$r, xlab="True", ylab="Inversion")
plot(res3 ~ dat$r, xlab="True", ylab="Feizi")
plot(res$b ~ dat$r, xlab="True", ylab="Total effects")

```

* * *

### Simulation 4 - five variables, causal chain

```{r }

dat <- init_dat(500000, 5)
dat <- make_edge(1,2,2, dat)
dat <- make_edge(2,3,3, dat)
dat <- make_edge(3,4,7, dat)
dat <- make_edge(4,5,4, dat)

res <- graph_mr(dat)
res1 <- mediation_method(res)
res2 <- inversion_method(res)
res3 <- deconvolution_method(res)

```

Increasing to 5 variables, and there is a clear problem with the mediation and Feizi methods

```{r, fig.cap="Graphs of five variables, N=500000" }

par(mfrow=c(2,3))
plot_from_matrix(dat$r, "True graph")
plot_from_matrix(res$b, "Total effects")
plot(1, type="n", axes=F, xlab="", ylab="")
plot_from_matrix(res1, "Mediation method")
plot_from_matrix(res2, "Inversion method")
plot_from_matrix(res3, "Feizi method")

```

The inversion method seems to be fairly reliable

```{r, fig.cap="Matrix elements of five variables, N=500000"}

par(mfrow=c(2,2))
plot(res1 ~ dat$r, xlab="True", ylab="Mediation")
plot(res2 ~ dat$r, xlab="True", ylab="Inversion")
plot(res3 ~ dat$r, xlab="True", ylab="Feizi")
plot(res$b ~ dat$r, xlab="True", ylab="Total effects")

```

* * *

### Simulation 5 - 15 variables

```{r }

p <- 15
dat <- init_dat(300000, p)
for(i in 1:(p-1))
{
	dat <- make_edge(i, i + 1, rnorm(1), dat)
}
# dat <- make_edge(1,7,rnorm(1), dat)
# dat <- make_edge(5,9,rnorm(1), dat)
# dat <- make_edge(3,12,rnorm(1), dat)
# dat <- make_edge(1,8,rnorm(1), dat)

res <- graph_mr(dat)
res2 <- inversion_method(res)
res3 <- deconvolution_method(res)

```

After around 7 variables the mediation method becomes too slow to run, so that will be ignored for the subsequent simulations. Here, with 15 variables there is still reasonably good performance from the inversion method.

```{r, fig.cap="Graphs of 15 variables, N=300000" }

par(mfrow=c(2,2))
plot_from_matrix(dat$r, "True graph")
plot_from_matrix(res$b, "Total effects")
plot_from_matrix(res2, "Inversion method")
plot_from_matrix(res3, "Feizi method")

```


```{r, fig.cap="Matrix elements of 15 variables, N=300000"}

par(mfrow=c(2,2))
plot(res2 ~ dat$r, xlab="True", ylab="Inversion")
plot(res3 ~ dat$r, xlab="True", ylab="Feizi")
plot(res$b ~ dat$r, xlab="True", ylab="Total effects")

```


* * *

### Simulation 6 - 20 variables, more complex

```{r }

p <- 20
dat <- init_dat(300000, p)
for(i in 1:(p-1))
{
	dat <- make_edge(i, i + 1, rnorm(1), dat)
}
dat <- make_edge(1,7,rnorm(1), dat)
dat <- make_edge(5,9,rnorm(1), dat)
dat <- make_edge(3,12,rnorm(1), dat)
dat <- make_edge(1,8,rnorm(1), dat)

res <- graph_mr(dat)
res2 <- inversion_method(res)
res3 <- deconvolution_method(res)

```

```{r, fig.cap="Graphs of 20 variables, N=300000" }

par(mfrow=c(2,2))
plot_from_matrix(dat$r, "True graph")
plot_from_matrix(res$b, "Total effects")
plot_from_matrix(res2, "Inversion method")
plot_from_matrix(res3, "Feizi method")

```

```{r, fig.cap="Matrix elements of 20 variables, N=300000"}

par(mfrow=c(2,2))
plot(res2 ~ dat$r, xlab="True", ylab="Inversion")
plot(res3 ~ dat$r, xlab="True", ylab="Feizi")
plot(res$b ~ dat$r, xlab="True", ylab="Total effects")

```

Here the inversion method has some issues, there are some indirect effects that should be set to 0 in the direct graph but have failed to have been removed.

* * *

### Simulation 7 - 30 variables, non-gaussian direct effects


```{r }

p <- 30
dat <- init_dat(300000, p)
for(i in 1:(p-1))
{
	dat <- make_edge(i, i + 1, rexp(1), dat)
}

res <- graph_mr(dat)
res2 <- inversion_method(res)
res3 <- deconvolution_method(res)

```

Here the effect sizes are sampled from an exponential distribution rather than a normal distribution. The inversion method seems relatively robust to this.

```{r, fig.cap="Graphs of 15 variables, N=300000" }

par(mfrow=c(2,2))
plot_from_matrix(dat$r, "True graph")
plot_from_matrix(res$b, "Total effects")
plot_from_matrix(res2, "Inversion method")
plot_from_matrix(res3, "Feizi method")

```


```{r, fig.cap="Matrix elements of 15 variables, N=300000"}

par(mfrow=c(2,2))
plot(res2 ~ dat$r, xlab="True", ylab="Inversion")
plot(res3 ~ dat$r, xlab="True", ylab="Feizi")
plot(res$b ~ dat$r, xlab="True", ylab="Total effects")

```


## Statistical power

As an illustration, in the following analyses a 5-trait network is created as in figure 1. Is it statistically more efficient to 

1. estimate the total effect of trait 1 on trait 5 using standard MR, or
2. obtain the direct effects of the 5-trait network, and estimate the causal chain from trait 1 -> 2 -> 3 -> 4 -> 5.

Strategy (2) entails finding a 'significant' p-value at each of the 4 direct relationships that map trait 1 to trait 5.


```{r}

test_sig <- function(res1, res1b)
{
	offdiag <- function(m, offset)
	{
		i <- seq_len(nrow(m)-offset)
		j <- i + offset
		m[cbind(i,j)]
	}

	n <- ncol(res1$b)
	total <- pnorm(abs(res1$b[n,1]/res1$se[n,1]), lower.tail=FALSE)
	chained <- max(offdiag(t(res1b$pval), 1))
	return(c(total, chained))
}

L <- list()
nsim <- 100
for(n in 3:6)
{
	message(n, " pos")
	l <- list()
	for(j in 1:nsim)
	{
		dat1 <- init_dat(5000, n)
		for(i in 1:(n-1))
		{
			dat1 <- make_edge(i, i+1, rnorm(1), dat1)
		}
		res1 <- graph_mr(dat1)
		res1b <- bootstrap_graphs(res1)
		l[[j]] <- test_sig(res1, res1b)
	}
	lpos <- as.data.frame(do.call(rbind, l))
	lpos$n <- n
	lpos$model <- "Non-null"

	message(n, " neg")
	l <- list()
	for(j in 1:nsim)
	{
		dat1 <- init_dat(5000, n)
		res1 <- graph_mr(dat1)
		res1b <- bootstrap_graphs(res1)
		l[[j]] <- test_sig(res1, res1b)
	}

	lneg <- as.data.frame(do.call(rbind, l))
	lneg$n <- n
	lneg$model <- "Null"

	L[[n]] <- rbind(lpos, lneg)
}
A <- bind_rows(L)

```

The simulation was performed using 5000 samples, and the simulated direct effect sizes for each chain were sampled from $\beta ~ N(0,1)$. 

```{r, fig.caption="Statistical power comparison between standard MR and graph MR using inversion method. Top graph shows the results from simulations where causal influences were simulated with non-zero effect sizes. Bottom graph shows depicts the false discovery rate, i.e. the same simulation but where all effect sizes are 0."}

AA <- gather(A, key='strategy', value='pval', V1, V2)
AA$strategy <- as.factor(AA$strategy)
levels(AA$strategy) <- c("Total effect", "Chained direct effects")

# ggplot(AA, aes(x=as.factor(n), y=-log10(pval))) +
# geom_boxplot(aes(fill=strategy)) +
# facet_grid(model ~ ., scale="free_y") +
# scale_y_log10() +
# labs(y="-log10(pval)", x="Graph size (e.g. number of traits from 1 to n)")

AAg <- AA %>% group_by(n, model, strategy) %>% summarise(propsig = sum(pval < 0.05))

ggplot(AAg, aes(x=as.factor(n), y=propsig)) +
geom_bar(stat="identity", aes(fill=strategy), position="dodge") +
facet_grid(model ~ .) +
labs(y=paste0("Number of simulations (out of ", nsim, ") with p < 0.05"), x="Graph size (e.g. number of traits from 1 to n)")

```



Here it is apparent that as the causal chain grows larger the statistical power of the second strategy, which uses the direct effects estimated from the graph, becomes substantially more powerful than the standard approach of identifying the total causal effect. The false discovery rate of the second strategy appears to compare favourably also.



## Discussion

The inversion method appears to be reasonably accurate in a range of scenarios, though not perfect when graphs become larger and relationships more complex. 


Issues:

- The mediation method might be interpreted too simplisticly here. I think there needs to be recursion beyond the 3 variable example - i.e. the direct effects are a function of indirect effects at the moment, but these indirect effects probably need to be reduced to direct effects also. This would require identifying a path through which to traverse the graph and recursively estimate the direct effects
- These simulations only looked at relatively sparse graphs, and with no loops.
- Why isn't the Feizi method working? Need to make sure it works for symmetric correlation graphs
- Need to estimate standard errors of direct effects. This could be obtained by bootstrapping
- Haven't evaluated the influence of cycles in the graph - this is hard to simulate though
- How does this improve power? e.g. If A influences F through B, C, D, and E, is it easier to identify the intermediate path than the direct relationship?
- Graphical lasso may be useful to make the matrix sparse

## References

